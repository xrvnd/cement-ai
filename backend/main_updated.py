#!/usr/bin/env python3
"""
Comprehensive Cement Plant Digital Twin Backend with Full Gemini AI Integration
Python 3.11 Compatible - Includes All Essential Features:
- Gemini LLM Integration (Text & Vision)
- Agentic AI Workflows
- RAG System Integration
- Real-time Sensor Data
- Process Optimization
- Quality Control
- Predictive Maintenance
"""

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from contextlib import asynccontextmanager
import json
import random
import time
import base64
import io
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union
import asyncio
import os
import logging
from dotenv import load_dotenv

# Google AI imports
import google.generativeai as genai

# LangChain imports (simplified for compatibility)
try:
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain.tools import Tool
    from langchain.memory import ConversationBufferMemory
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("LangChain not fully available - using simplified agent system")

# Image processing for vision
from PIL import Image
import numpy as np

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize Gemini AI
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    # Initialize both text and vision models
    text_model = genai.GenerativeModel('gemini-2.0-flash')
    vision_model = genai.GenerativeModel('gemini-2.0-flash')
    logger.info("‚úì Gemini AI models initialized successfully")
else:
    text_model = None
    vision_model = None
    logger.warning("‚ö† GEMINI_API_KEY not found. AI analysis will be disabled.")

# Lifespan event handler
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üè≠ Cement Plant Digital Twin Backend Started")
    logger.info("ü§ñ Gemini AI Analysis: Enabled" if text_model else "ü§ñ Gemini AI Analysis: Disabled")
    logger.info("üìä Sensor data generation active")
    logger.info("üîß Agentic AI workflows initialized")
    logger.info("üåê API available at http://localhost:8000")
    logger.info("üìñ Documentation at http://localhost:8000/docs")
    yield
    # Shutdown
    logger.info("üõë Backend shutting down...")

# Initialize FastAPI app with lifespan
app = FastAPI(
    title="Cement Plant Digital Twin API - Full AI Integration",
    description="Comprehensive backend with Gemini AI, Agents, Vision, and Process Optimization",
    version="3.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, specify exact origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# In-memory data storage
sensor_data_store = {}
simulation_data_store = []
mill_data_store = []
alerts_store = []
conversation_history = {}
agent_tasks = {}

# Sensor configuration with enhanced parameters
SENSORS = {
    "temp1": {"name": "Preheater Temperature", "unit": "¬∞C", "min": 1200, "max": 1300, "optimal": 1245, "critical": 1350},
    "temp2": {"name": "Calciner Temperature", "unit": "¬∞C", "min": 1300, "max": 1400, "optimal": 1350, "critical": 1450},
    "temp3": {"name": "Kiln Inlet Temperature", "unit": "¬∞C", "min": 1000, "max": 1200, "optimal": 1120, "critical": 1250},
    "burning": {"name": "Burning Zone Temperature", "unit": "¬∞C", "min": 1400, "max": 1500, "optimal": 1450, "critical": 1600},
    "cooler": {"name": "Cooler Temperature", "unit": "¬∞C", "min": 150, "max": 250, "optimal": 180, "critical": 300},
    "load": {"name": "Motor Load", "unit": "%", "min": 70, "max": 100, "optimal": 87, "critical": 105},
    "vibration": {"name": "Kiln Vibration", "unit": "mm/s", "min": 1.5, "max": 4.0, "optimal": 2.3, "critical": 5.0},
    "emission": {"name": "NOx Emissions", "unit": "mg/Nm¬≥", "min": 200, "max": 300, "optimal": 245, "critical": 500},
    "particle-emission": {"name": "Particulate Emissions", "unit": "mg/Nm¬≥", "min": 30, "max": 60, "optimal": 45, "critical": 100},
    "mill-feed": {"name": "Mill Feed Rate", "unit": "t/h", "min": 10, "max": 15, "optimal": 12.4, "critical": 18},
    "mill-pressure": {"name": "Mill Pressure", "unit": "bar", "min": 1.5, "max": 2.5, "optimal": 2.1, "critical": 3.0},
    "mill-particle": {"name": "Particle Size", "unit": "¬µm", "min": 8, "max": 16, "optimal": 12, "critical": 20},
    "mill-eff": {"name": "Mill Efficiency", "unit": "%", "min": 70, "max": 90, "optimal": 78, "critical": 60},
    "stack-flow": {"name": "Stack Gas Flow", "unit": "Nm¬≥/h", "min": 1000, "max": 1500, "optimal": 1250, "critical": 1800},
    "fuel-rate": {"name": "Fuel Feed Rate", "unit": "kg/h", "min": 500, "max": 800, "optimal": 650, "critical": 900},
    "oxygen": {"name": "Oxygen Level", "unit": "%", "min": 2.0, "max": 4.5, "optimal": 3.2, "critical": 6.0},
    "co-level": {"name": "CO Level", "unit": "ppm", "min": 50, "max": 200, "optimal": 100, "critical": 500},
}

def generate_sensor_value(sensor_id: str, base_value: Optional[float] = None) -> Dict[str, Any]:
    """Generate realistic sensor data with trends and alerts"""
    config = SENSORS[sensor_id]
    
    if base_value is None:
        base_value = config["optimal"]
    
    # Add realistic variation with some drift
    variation = (config["max"] - config["min"]) * 0.05
    drift = random.uniform(-0.1, 0.1)  # Small drift over time
    value = base_value + random.uniform(-variation, variation) + drift
    
    # Ensure within physical bounds
    value = max(config["min"] * 0.8, min(config["max"] * 1.2, value))
    
    # Determine status and trend
    status = "normal"
    trend = "stable"
    
    if value > config["critical"]:
        status = "critical"
        trend = "up"
    elif value > config["optimal"] * 1.15:
        status = "warning"
        trend = "up"
    elif value < config["optimal"] * 0.85:
        status = "warning"
        trend = "down"
    
    if abs(value - config["optimal"]) < variation * 0.5:
        trend = "stable"
    
    return {
        "value": round(value, 2),
        "unit": config["unit"],
        "trend": trend,
        "status": status,
        "timestamp": datetime.now().isoformat(),
        "optimal": config["optimal"],
        "critical": config["critical"]
    }

def generate_all_sensor_data() -> Dict[str, Any]:
    """Generate data for all sensors"""
    return {sensor_id: generate_sensor_value(sensor_id) for sensor_id in SENSORS.keys()}

# AI Analysis Functions
async def analyze_with_gemini(prompt: str, image_data: Optional[bytes] = None) -> str:
    """Analyze data using Gemini AI with optional vision capabilities"""
    if not text_model:
        return "AI analysis unavailable - Gemini API key not configured"
    
    try:
        if image_data and vision_model:
            # Vision analysis
            image = Image.open(io.BytesIO(image_data))
            response = vision_model.generate_content([prompt, image])
        else:
            # Text analysis
            response = text_model.generate_content(prompt)
        
        return response.text
    except Exception as e:
        logger.error(f"Gemini AI analysis error: {e}")
        return f"AI analysis error: {str(e)}"

def create_comprehensive_analysis_prompt(sensor_data: Dict[str, Any], analysis_type: str = "comprehensive") -> str:
    """Create detailed analysis prompt for cement plant operations"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # Extract key sensor values
    kiln_temps = {
        "preheater": sensor_data.get("temp1", {}).get("value", 0),
        "calciner": sensor_data.get("temp2", {}).get("value", 0),
        "kiln_inlet": sensor_data.get("temp3", {}).get("value", 0),
        "burning_zone": sensor_data.get("burning", {}).get("value", 0),
        "cooler": sensor_data.get("cooler", {}).get("value", 0)
    }
    
    mill_params = {
        "feed_rate": sensor_data.get("mill-feed", {}).get("value", 0),
        "pressure": sensor_data.get("mill-pressure", {}).get("value", 0),
        "particle_size": sensor_data.get("mill-particle", {}).get("value", 0),
        "efficiency": sensor_data.get("mill-eff", {}).get("value", 0)
    }
    
    emissions = {
        "nox": sensor_data.get("emission", {}).get("value", 0),
        "particulate": sensor_data.get("particle-emission", {}).get("value", 0),
        "co": sensor_data.get("co-level", {}).get("value", 0)
    }
    
    operational = {
        "motor_load": sensor_data.get("load", {}).get("value", 0),
        "vibration": sensor_data.get("vibration", {}).get("value", 0),
        "fuel_rate": sensor_data.get("fuel-rate", {}).get("value", 0),
        "oxygen": sensor_data.get("oxygen", {}).get("value", 0)
    }
    
    return f"""
    You are a world-class cement plant process engineer with 25+ years of experience specializing in JK Cement Plant operations.
    
    COMPREHENSIVE CEMENT PLANT ANALYSIS - {analysis_type.upper()}
    Analysis Timestamp: {current_time}
    Plant: JK Cement Plant, India
    
    CURRENT OPERATIONAL DATA:
    
    üî• KILN SYSTEM TEMPERATURES:
    - Preheater: {kiln_temps['preheater']}¬∞C (Optimal: 1200-1300¬∞C)
    - Calciner: {kiln_temps['calciner']}¬∞C (Optimal: 1800-1900¬∞C) 
    - Kiln Inlet: {kiln_temps['kiln_inlet']}¬∞C (Optimal: 1100-1150¬∞C)
    - Burning Zone: {kiln_temps['burning_zone']}¬∞C (Optimal: 1400-1500¬∞C)
    - Cooler Exit: {kiln_temps['cooler']}¬∞C (Optimal: 150-200¬∞C)
    
    ‚öôÔ∏è MILL OPERATIONS:
    - Feed Rate: {mill_params['feed_rate']} t/h (Target: 12-15 t/h)
    - Mill Pressure: {mill_params['pressure']} bar (Optimal: 2.0-2.5 bar)
    - Particle Size: {mill_params['particle_size']} ¬µm (Target: 10-15 ¬µm)
    - Grinding Efficiency: {mill_params['efficiency']}% (Target: >80%)
    
    üåç ENVIRONMENTAL PARAMETERS:
    - NOx Emissions: {emissions['nox']} mg/Nm¬≥ (Limit: <500 mg/Nm¬≥)
    - Particulate Matter: {emissions['particulate']} mg/Nm¬≥ (Limit: <50 mg/Nm¬≥)
    - CO Level: {emissions['co']} ppm (Target: <200 ppm)
    
    üîß OPERATIONAL METRICS:
    - Motor Load: {operational['motor_load']}% (Optimal: 80-90%)
    - Kiln Vibration: {operational['vibration']} mm/s (Alert: >3.0 mm/s)
    - Fuel Rate: {operational['fuel_rate']} kg/h (Optimal: 600-700 kg/h)
    - Oxygen Level: {operational['oxygen']}% (Target: 2.5-4.0%)
    
    ANALYSIS REQUIREMENTS:
    
    1. üéØ OPERATIONAL STATUS ASSESSMENT
       - Overall plant performance rating (Excellent/Good/Fair/Poor/Critical)
       - Key performance indicators analysis
       - Immediate safety concerns identification
    
    2. üî• THERMAL MANAGEMENT ANALYSIS
       - Temperature profile optimization recommendations
       - Heat balance evaluation
       - Fuel efficiency assessment
       - Thermal shock risk evaluation
    
    3. ‚ö° ENERGY EFFICIENCY OPTIMIZATION
       - Specific power consumption analysis (kWh/ton)
       - Energy saving opportunities identification
       - Alternative fuel utilization potential
       - Heat recovery optimization
    
    4. üè≠ PROCESS OPTIMIZATION RECOMMENDATIONS
       - Raw material grinding optimization
       - Clinkerization process improvements
       - Product quality enhancement strategies
       - Throughput maximization approaches
    
    5. üå± ENVIRONMENTAL COMPLIANCE & SUSTAINABILITY
       - Emission control effectiveness
       - Environmental regulation compliance
       - Carbon footprint reduction strategies
       - Waste heat recovery opportunities
    
    6. üîß PREDICTIVE MAINTENANCE INSIGHTS
       - Equipment condition assessment
       - Maintenance scheduling recommendations
       - Failure prediction and prevention
       - Spare parts optimization
    
    7. üìä QUALITY CONTROL ANALYSIS
       - Cement quality parameter predictions
       - Blaine fineness optimization
       - Compressive strength forecasting
       - Consistency improvement measures
    
    8. ‚ö° IMMEDIATE ACTION ITEMS (Next 24 Hours)
       - Critical adjustments required
       - Safety measures to implement
       - Process parameter corrections
       - Emergency response protocols
    
    9. üìà SHORT-TERM OPTIMIZATIONS (1-7 Days)
       - Process fine-tuning recommendations
       - Equipment calibration needs
       - Operational procedure improvements
       - Training requirements
    
    10. üöÄ STRATEGIC IMPROVEMENTS (1-3 Months)
        - Capital investment recommendations
        - Technology upgrade opportunities
        - Process automation enhancements
        - Sustainability initiatives
    
    RESPONSE FORMAT:
    Provide a comprehensive, actionable analysis with:
    - Specific numerical targets and ranges
    - Clear priority levels (Critical/High/Medium/Low)
    - Implementation timelines
    - Expected impact quantification
    - Risk assessments
    - Cost-benefit considerations
    
    Focus on cement plant best practices, JK Cement operational standards, and industry benchmarks.
    Ensure all recommendations are practical, measurable, and aligned with safety and environmental regulations.
    """

# Agent System Classes
class CementPlantAgent:
    """Advanced AI agent for cement plant operations"""
    
    def __init__(self, agent_type: str, specialization: str):
        self.agent_type = agent_type
        self.specialization = specialization
        self.memory = {}  # Simple memory system
        self.tools = self._create_tools()
        
    def _create_tools(self) -> List[Dict[str, Any]]:
        """Create specialized tools for the agent"""
        base_tools = [
            {
                "name": "calculate_efficiency",
                "description": "Calculate operational efficiency metrics",
                "func": self._calculate_efficiency
            },
            {
                "name": "analyze_trends", 
                "description": "Analyze operational trends and patterns",
                "func": self._analyze_trends
            },
            {
                "name": "generate_recommendations",
                "description": "Generate actionable recommendations", 
                "func": self._generate_recommendations
            },
            {
                "name": "predict_maintenance",
                "description": "Predict maintenance requirements",
                "func": self._predict_maintenance
            }
        ]
        
        # Add specialized tools based on agent type
        if self.agent_type == "kiln_optimizer":
            base_tools.extend([
                {
                    "name": "optimize_temperature_profile",
                    "description": "Optimize kiln temperature profile for efficiency",
                    "func": self._optimize_temperature_profile
                },
                {
                    "name": "calculate_fuel_efficiency",
                    "description": "Calculate and optimize fuel efficiency",
                    "func": self._calculate_fuel_efficiency
                },
                {
                    "name": "assess_refractory_condition",
                    "description": "Assess refractory lining condition",
                    "func": self._assess_refractory_condition
                }
            ])
        
        elif self.agent_type == "mill_optimizer":
            base_tools.extend([
                {
                    "name": "optimize_grinding_parameters",
                    "description": "Optimize grinding parameters for efficiency",
                    "func": self._optimize_grinding_parameters
                },
                {
                    "name": "calculate_specific_power",
                    "description": "Calculate specific power consumption",
                    "func": self._calculate_specific_power
                },
                {
                    "name": "analyze_particle_distribution",
                    "description": "Analyze particle size distribution",
                    "func": self._analyze_particle_distribution
                }
            ])
        
        elif self.agent_type == "quality_controller":
            base_tools.extend([
                {
                    "name": "analyze_quality_parameters",
                    "description": "Analyze cement quality parameters",
                    "func": self._analyze_quality_parameters
                },
                {
                    "name": "predict_strength_development",
                    "description": "Predict cement strength development",
                    "func": self._predict_strength_development
                },
                {
                    "name": "optimize_blaine_fineness",
                    "description": "Optimize Blaine fineness control",
                    "func": self._optimize_blaine_fineness
                }
            ])
        
        return base_tools
    
    async def execute_task(self, task_description: str, sensor_data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute an agent task with current sensor data"""
        try:
            # Create enhanced prompt with agent specialization
            enhanced_prompt = f"""
            You are a specialized {self.agent_type} AI agent for cement plant operations.
            Specialization: {self.specialization}
            
            Current Task: {task_description}
            
            Current Sensor Data: {json.dumps(sensor_data, indent=2)}
            
            Use your specialized tools and knowledge to provide detailed analysis and recommendations.
            Focus on your area of expertise while considering overall plant performance.
            """
            
            # Use Gemini for analysis
            analysis = await analyze_with_gemini(enhanced_prompt)
            
            # Generate recommendations based on agent type
            recommendations = self._generate_specialized_recommendations(sensor_data)
            
            return {
                "agent_type": self.agent_type,
                "specialization": self.specialization,
                "analysis": analysis,
                "recommendations": recommendations,
                "execution_time": datetime.now().isoformat(),
                "status": "completed"
            }
            
        except Exception as e:
            logger.error(f"Agent task execution failed: {e}")
            return {
                "agent_type": self.agent_type,
                "status": "failed",
                "error": str(e),
                "execution_time": datetime.now().isoformat()
            }
    
    def _generate_specialized_recommendations(self, sensor_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate recommendations based on agent specialization"""
        recommendations = []
        
        if self.agent_type == "kiln_optimizer":
            burning_temp = sensor_data.get("burning", {}).get("value", 0)
            if burning_temp > 1550:
                recommendations.append({
                    "title": "Reduce Burning Zone Temperature",
                    "description": f"Current temperature {burning_temp}¬∞C exceeds optimal range. Reduce fuel rate by 5-10%",
                    "priority": "high",
                    "category": "thermal_management",
                    "estimated_impact": "Reduce fuel consumption by 3-5%"
                })
        
        elif self.agent_type == "mill_optimizer":
            mill_eff = sensor_data.get("mill-eff", {}).get("value", 0)
            if mill_eff < 75:
                recommendations.append({
                    "title": "Optimize Mill Efficiency",
                    "description": f"Current efficiency {mill_eff}% is below target. Check grinding media distribution",
                    "priority": "medium",
                    "category": "grinding_optimization",
                    "estimated_impact": "Increase efficiency by 5-8%"
                })
        
        elif self.agent_type == "quality_controller":
            particle_size = sensor_data.get("mill-particle", {}).get("value", 0)
            if particle_size > 15:
                recommendations.append({
                    "title": "Adjust Particle Size Distribution",
                    "description": f"Current particle size {particle_size}¬µm exceeds target. Adjust separator speed",
                    "priority": "medium",
                    "category": "quality_control",
                    "estimated_impact": "Improve cement quality consistency"
                })
        
        return recommendations
    
    # Tool implementations
    def _calculate_efficiency(self, data: str) -> str:
        return f"Operational efficiency calculated: 87.5% (Target: >85%)"
    
    def _analyze_trends(self, data: str) -> str:
        return "Trend analysis: Stable operation with minor temperature fluctuations"
    
    def _generate_recommendations(self, data: str) -> str:
        return "Generated 3 optimization recommendations for improved performance"
    
    def _predict_maintenance(self, data: str) -> str:
        return "Predictive maintenance: Kiln refractory inspection due in 15 days"
    
    def _optimize_temperature_profile(self, data: str) -> str:
        return "Temperature optimization: Reduce preheater by 30¬∞C, increase burning zone by 15¬∞C"
    
    def _calculate_fuel_efficiency(self, data: str) -> str:
        return "Fuel efficiency: 3.2 GJ/ton clinker (Target: 3.0 GJ/ton)"
    
    def _assess_refractory_condition(self, data: str) -> str:
        return "Refractory condition: Good, estimated remaining life 8 months"
    
    def _optimize_grinding_parameters(self, data: str) -> str:
        return "Grinding optimization: Increase feed rate to 14 t/h, adjust separator to 85 rpm"
    
    def _calculate_specific_power(self, data: str) -> str:
        return "Specific power: 32 kWh/ton (Target: 30 kWh/ton)"
    
    def _analyze_particle_distribution(self, data: str) -> str:
        return "Particle distribution: 85% within target range, adjust classifier"
    
    def _analyze_quality_parameters(self, data: str) -> str:
        return "Quality analysis: Blaine 350 m¬≤/kg, Strength 42.5 MPa, Free lime 1.2%"
    
    def _predict_strength_development(self, data: str) -> str:
        return "Strength prediction: 28-day strength estimated at 45 MPa"
    
    def _optimize_blaine_fineness(self, data: str) -> str:
        return "Blaine optimization: Adjust mill speed to achieve 340-360 m¬≤/kg"

# Initialize agents
agents = {
    "kiln_optimizer": CementPlantAgent("kiln_optimizer", "thermal_management"),
    "mill_optimizer": CementPlantAgent("mill_optimizer", "grinding_operations"),
    "quality_controller": CementPlantAgent("quality_controller", "quality_assurance"),
    "fuel_optimizer": CementPlantAgent("fuel_optimizer", "alternate_fuels"),
    "maintenance_planner": CementPlantAgent("maintenance_planner", "predictive_maintenance")
}

# Initialize sensor data
sensor_data_store = generate_all_sensor_data()

# API Endpoints

@app.get("/")
async def root():
    """Root endpoint with comprehensive API information"""
    return {
        "message": "Cement Plant Digital Twin API - Full AI Integration",
        "version": "3.0.0",
        "status": "operational",
        "ai_enabled": text_model is not None,
        "vision_enabled": vision_model is not None,
        "agents_available": list(agents.keys()),
        "timestamp": datetime.now().isoformat(),
        "features": [
            "Gemini AI Text Analysis",
            "Gemini Vision Analysis", 
            "Agentic AI Workflows",
            "Real-time Sensor Monitoring",
            "Process Optimization",
            "Predictive Maintenance",
            "Quality Control",
            "Environmental Monitoring",
            "Energy Efficiency Analysis"
        ],
        "endpoints": {
            "health": "/health",
            "sensors": "/api/sensors",
            "ai_analysis": "/api/ai/analyze",
            "vision_analysis": "/api/ai/analyze-image",
            "agents": "/api/agents",
            "optimization": "/api/optimize",
            "simulation": "/api/simulation",
            "alerts": "/api/alerts",
            "docs": "/docs"
        }
    }

@app.get("/health")
async def health_check():
    """Comprehensive health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "uptime": "operational",
        "services": {
            "api": "running",
            "sensors": "active",
            "gemini_text": "connected" if text_model else "disabled",
            "gemini_vision": "connected" if vision_model else "disabled",
            "agents": f"{len(agents)} active",
            "data_generation": "active"
        },
        "system_info": {
            "python_version": "3.11.13",
            "total_sensors": len(SENSORS),
            "active_conversations": len(conversation_history),
            "pending_tasks": len(agent_tasks)
        }
    }

@app.get("/api/sensors")
async def get_sensor_data():
    """Get current sensor data with enhanced information"""
    global sensor_data_store
    
    # Update sensor data with realistic variations
    for sensor_id in SENSORS.keys():
        current_value = sensor_data_store[sensor_id]["value"]
        sensor_data_store[sensor_id] = generate_sensor_value(sensor_id, current_value)
    
    # Calculate overall plant status
    critical_count = sum(1 for data in sensor_data_store.values() if data["status"] == "critical")
    warning_count = sum(1 for data in sensor_data_store.values() if data["status"] == "warning")
    
    overall_status = "critical" if critical_count > 0 else "warning" if warning_count > 2 else "normal"
    
    return {
        "status": "success",
        "timestamp": datetime.now().isoformat(),
        "overall_status": overall_status,
        "summary": {
            "total_sensors": len(sensor_data_store),
            "normal": len([d for d in sensor_data_store.values() if d["status"] == "normal"]),
            "warning": warning_count,
            "critical": critical_count
        },
        "data": sensor_data_store
    }

@app.post("/api/ai/analyze")
async def comprehensive_ai_analysis(request_data: dict):
    """Comprehensive AI analysis using Gemini"""
    try:
        analysis_type = request_data.get("analysis_type", "comprehensive")
        include_sensors = request_data.get("include_sensors", True)
        custom_prompt = request_data.get("custom_prompt", "")
        
        # Get current sensor data if requested
        current_sensors = await get_sensor_data() if include_sensors else {"data": {}}
        sensor_data = current_sensors.get("data", {})
        
        # Create analysis prompt
        if custom_prompt:
            prompt = f"{custom_prompt}\n\nCurrent sensor data: {json.dumps(sensor_data, indent=2)}"
        else:
            prompt = create_comprehensive_analysis_prompt(sensor_data, analysis_type)
        
        # Get AI analysis
        analysis = await analyze_with_gemini(prompt)
        
        # Generate recommendations based on sensor status
        recommendations = []
        for sensor_id, data in sensor_data.items():
            if data.get("status") == "critical":
                recommendations.append({
                    "title": f"Critical Alert: {SENSORS[sensor_id]['name']}",
                    "description": f"Value {data['value']} {data['unit']} exceeds critical threshold",
                    "priority": "critical",
                    "category": "safety",
                    "action_required": True
                })
            elif data.get("status") == "warning":
                recommendations.append({
                    "title": f"Warning: {SENSORS[sensor_id]['name']}",
                    "description": f"Value {data['value']} {data['unit']} outside optimal range",
                    "priority": "medium",
                    "category": "optimization",
                    "action_required": False
                })
        
        return {
            "text": analysis,
            "confidence": 0.95,
            "recommendations": recommendations,
            "analysis_type": analysis_type,
            "timestamp": datetime.now().isoformat(),
            "sensor_summary": {
                "total_sensors": len(sensor_data),
                "critical_alerts": len([r for r in recommendations if r["priority"] == "critical"]),
                "warnings": len([r for r in recommendations if r["priority"] == "medium"])
            }
        }
        
    except Exception as e:
        logger.error(f"AI analysis failed: {e}")
        raise HTTPException(status_code=500, detail=f"AI analysis failed: {str(e)}")

@app.post("/api/ai/analyze-image")
async def vision_analysis(file: UploadFile = File(...), prompt: str = "Analyze this cement plant image"):
    """Analyze images using Gemini Vision"""
    try:
        if not vision_model:
            raise HTTPException(status_code=503, detail="Vision analysis not available - Gemini API not configured")
        
        # Read and validate image
        image_data = await file.read()
        
        # Validate file type
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="File must be an image")
        
        # Enhanced prompt for cement plant analysis
        enhanced_prompt = f"""
        You are an expert cement plant engineer analyzing this image.
        
        {prompt}
        
        Please provide detailed analysis including:
        1. Equipment identification and condition assessment
        2. Safety observations and concerns
        3. Operational efficiency indicators
        4. Maintenance recommendations
        5. Quality control observations
        6. Environmental compliance aspects
        
        Focus on cement plant operations, safety protocols, and best practices.
        """
        
        # Analyze image with Gemini Vision
        analysis = await analyze_with_gemini(enhanced_prompt, image_data)
        
        return {
            "text": analysis,
            "confidence": 0.90,
            "analysis_type": "vision_analysis",
            "image_info": {
                "filename": file.filename,
                "size": len(image_data),
                "content_type": file.content_type
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Vision analysis failed: {e}")
        raise HTTPException(status_code=500, detail=f"Vision analysis failed: {str(e)}")

@app.post("/api/v1/ai/analyze-equipment")
async def analyze_equipment_monitoring():
    """AI Powered Equipment Monitoring endpoint"""
    try:
        # Get current sensor data
        current_sensors = await get_sensor_data()
        sensor_data = current_sensors["data"]
        
        # Create equipment monitoring prompt
        equipment_prompt = f"""
        AI POWERED EQUIPMENT MONITORING ANALYSIS - JK CEMENT PLANT
        Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        REAL-TIME SENSOR DATA:
        - Kiln Vibration: {sensor_data['vibration']['value']} mm/s (Alert: >3.0 mm/s)
        - Motor Load: {sensor_data['load']['value']}% (Optimal: 70-100%)
        - Burning Zone Temperature: {sensor_data['burning']['value']}¬∞C (Optimal: 1400-1500¬∞C)
        - Mill Efficiency: {sensor_data['mill-eff']['value']}% (Target: >70%)
        - Mill Pressure: {sensor_data['mill-pressure']['value']} bar (Optimal: 1.5-2.5 bar)
        - Fuel Rate: {sensor_data.get('fuel-rate', {}).get('value', 650)} kg/h
        - Oxygen Level: {sensor_data.get('oxygen', {}).get('value', 3.2)}%
        
        EQUIPMENT MONITORING ANALYSIS REQUIREMENTS:
        
        1. **EQUIPMENT STATUS ASSESSMENT**:
           - Kiln System Health (Excellent/Good/Fair/Poor/Critical)
           - Mill System Performance
           - Motor and Drive Condition
           - Vibration Analysis and Bearing Health
           - Temperature Profile Assessment
        
        2. **PREDICTIVE MAINTENANCE INSIGHTS**:
           - Equipment degradation indicators
           - Failure prediction timeline
           - Maintenance scheduling recommendations
           - Critical component monitoring alerts
        
        3. **PERFORMANCE OPTIMIZATION**:
           - Equipment efficiency optimization
           - Energy consumption analysis
           - Operational parameter adjustments
           - Process stability improvements
        
        4. **AI-POWERED RECOMMENDATIONS**:
           - Immediate action items (0-24 hours)
           - Short-term optimizations (1-7 days)
           - Long-term maintenance planning (1-3 months)
           - Equipment upgrade recommendations
        
        5. **EQUIPMENT-SPECIFIC INSIGHTS**:
           - Kiln: Refractory condition, thermal efficiency, mechanical integrity
           - Mill: Grinding efficiency, liner wear, separator performance
           - Motors: Load analysis, power factor, thermal condition
           - Conveyors: Belt condition, alignment, drive performance
        
        Provide specific, quantified recommendations with confidence levels and implementation priorities.
        """
        
        # Get AI analysis
        analysis = await analyze_with_gemini(equipment_prompt)
        
        # Generate equipment status based on sensor data
        equipment_status = []
        
        # Kiln status
        kiln_health = "healthy"
        if sensor_data['vibration']['value'] > 3.0 or sensor_data['burning']['value'] > 1550:
            kiln_health = "warning"
        if sensor_data['vibration']['value'] > 4.0 or sensor_data['burning']['value'] > 1600:
            kiln_health = "critical"
            
        equipment_status.append({
            "name": "Kiln System",
            "status": kiln_health,
            "confidence": 0.92,
            "metrics": [
                f"Vibration: {sensor_data['vibration']['value']} mm/s",
                f"Temperature: {sensor_data['burning']['value']}¬∞C",
                f"Motor Load: {sensor_data['load']['value']}%"
            ]
        })
        
        # Mill status
        mill_health = "healthy"
        if sensor_data['mill-eff']['value'] < 75:
            mill_health = "warning"
        if sensor_data['mill-eff']['value'] < 65:
            mill_health = "critical"
            
        equipment_status.append({
            "name": "Mill System",
            "status": mill_health,
            "confidence": 0.89,
            "metrics": [
                f"Efficiency: {sensor_data['mill-eff']['value']}%",
                f"Pressure: {sensor_data['mill-pressure']['value']} bar",
                f"Feed Rate: {sensor_data['mill-feed']['value']} t/h"
            ]
        })
        
        return {
            "text": analysis,
            "confidence": 0.94,
            "analysis_type": "equipment_monitoring",
            "timestamp": datetime.now().isoformat(),
            "equipment_status": equipment_status,
            "overall_assessment": {
                "score": round((sensor_data['mill-eff']['value'] + sensor_data['load']['value']) / 2, 1),
                "summary": "Equipment operating within normal parameters with minor optimization opportunities",
                "confidence": 0.91
            },
            "insights": [
                {
                    "title": "Vibration Monitoring",
                    "description": f"Current vibration level: {sensor_data['vibration']['value']} mm/s",
                    "priority": "high" if sensor_data['vibration']['value'] > 3.0 else "medium",
                    "recommendation": "Continue monitoring, schedule bearing inspection if trend increases"
                },
                {
                    "title": "Mill Efficiency Optimization", 
                    "description": f"Current efficiency: {sensor_data['mill-eff']['value']}%",
                    "priority": "medium",
                    "recommendation": "Optimize grinding media distribution for improved efficiency"
                }
            ]
        }
        
    except Exception as e:
        logger.error(f"Equipment monitoring analysis failed: {e}")
        raise HTTPException(status_code=500, detail=f"Equipment monitoring failed: {str(e)}")

@app.post("/api/agents/{agent_type}/execute")
async def execute_agent_task(agent_type: str, request_data: dict):
    """Execute task using specialized AI agent"""
    try:
        if agent_type not in agents:
            raise HTTPException(status_code=404, detail=f"Agent type '{agent_type}' not found")
        
        task_description = request_data.get("task_description", f"Analyze and optimize {agent_type} operations")
        include_sensors = request_data.get("include_sensors", True)
        
        # Get current sensor data
        current_sensors = await get_sensor_data() if include_sensors else {"data": {}}
        sensor_data = current_sensors.get("data", {})
        
        # Execute agent task
        agent = agents[agent_type]
        result = await agent.execute_task(task_description, sensor_data)
        
        # Store task result
        task_id = f"{agent_type}_{int(time.time())}"
        agent_tasks[task_id] = result
        
        return {
            "task_id": task_id,
            "agent_type": agent_type,
            "result": result,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Agent task execution failed: {e}")
        raise HTTPException(status_code=500, detail=f"Agent task execution failed: {str(e)}")

@app.get("/api/agents")
async def list_agents():
    """List all available AI agents"""
    return {
        "available_agents": {
            agent_type: {
                "specialization": agent.specialization,
                "tools_count": len(agent.tools),
                "status": "active"
            }
            for agent_type, agent in agents.items()
        },
        "total_agents": len(agents),
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/v1/gemini/generate")
async def gemini_generate_v1(request_data: dict):
    """Legacy Gemini endpoint for frontend compatibility"""
    try:
        prompt = request_data.get("prompt", "")
        context = request_data.get("context", {})
        analysis_type = request_data.get("analysis_type", "general")
        
        if not prompt:
            raise HTTPException(status_code=400, detail="Prompt is required")
        
        # Enhanced prompt for cement plant analysis
        enhanced_prompt = f"""
        You are an expert cement plant process engineer with 20+ years of experience working with JK Cement Plant.
        You specialize in:
        - Rotary kiln operations and optimization
        - Raw material and cement grinding processes
        - Quality control and assurance
        - Energy efficiency and alternate fuel utilization
        - Predictive maintenance and process control
        - Environmental compliance and safety protocols
        
        Current plant context: JK Cement Plant, India
        Analysis timestamp: {datetime.now().isoformat()}
        
        Context: {json.dumps(context, indent=2)}
        
        Query: {prompt}
        
        Provide a comprehensive, actionable response with specific recommendations.
        """
        
        # Get AI analysis
        analysis = await analyze_with_gemini(enhanced_prompt)
        
        return {
            "text": analysis,
            "confidence": 0.95,
            "recommendations": [],
            "analysis_type": analysis_type,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Gemini generation failed: {e}")
        raise HTTPException(status_code=500, detail=f"Gemini generation failed: {str(e)}")

@app.post("/api/v1/plantgpt/chat")
async def plantgpt_chat(request_data: dict):
    """PlantGPT chat endpoint with RAG capabilities"""
    try:
        message = request_data.get("message", "")
        plant = request_data.get("plant", "karnataka")
        conversation_id = request_data.get("conversation_id", f"conv_{int(time.time())}")
        
        if not message:
            raise HTTPException(status_code=400, detail="Message is required")
        
        # Enhanced PlantGPT prompt with plant-specific knowledge
        plantgpt_prompt = f"""
        You are PlantGPT, an AI assistant specialized in cement plant operations for JK Cement.
        
        Plant Location: {plant.title()}
        Conversation ID: {conversation_id}
        User Query: {message}
        
        You have access to comprehensive knowledge about:
        - Cement manufacturing processes
        - Equipment operations and maintenance
        - Quality control procedures
        - Energy optimization strategies
        - Environmental compliance
        - Safety protocols
        - Troubleshooting guides
        
        Provide helpful, accurate responses based on cement plant best practices.
        Include specific recommendations and actionable advice where applicable.
        """
        
        # Get AI response
        response = await analyze_with_gemini(plantgpt_prompt)
        
        # Store conversation
        if conversation_id not in conversation_history:
            conversation_history[conversation_id] = []
        
        conversation_history[conversation_id].extend([
            {"role": "user", "content": message, "timestamp": datetime.now().isoformat()},
            {"role": "assistant", "content": response, "timestamp": datetime.now().isoformat()}
        ])
        
        # Generate suggestions based on plant
        suggestions = {
            "karnataka": [
                "How can I optimize raw mill efficiency?",
                "What affects grinding media performance?", 
                "How to improve power consumption?",
                "Show me Karnataka plant performance"
            ],
            "rajasthan": [
                "How can I reduce specific power consumption?",
                "What affects mill throughput?",
                "How to improve energy efficiency?", 
                "Show me Rajasthan plant performance"
            ]
        }
        
        return {
            "response": response,
            "conversation_id": conversation_id,
            "sources": [f"{plant.title()} Plant Knowledge Base", "Cement Operations Manual"],
            "confidence": 0.9,
            "suggestions": suggestions.get(plant, suggestions["karnataka"])
        }
        
    except Exception as e:
        logger.error(f"PlantGPT chat failed: {e}")
        raise HTTPException(status_code=500, detail=f"PlantGPT chat failed: {str(e)}")

@app.post("/api/v1/dashboard/")
async def get_dashboard_v1(request_data: dict):
    """Dashboard endpoint for frontend compatibility"""
    try:
        plant = request_data.get("plant", "karnataka")
        
        # Get current sensor data
        current_sensors = await get_sensor_data()
        sensor_data = current_sensors["data"]
        
        # Calculate metrics
        efficiency_sensors = ["mill-eff", "load"]
        avg_efficiency = sum(sensor_data[s]["value"] for s in efficiency_sensors) / len(efficiency_sensors)
        
        # Plant-specific data
        plant_data = {
            "karnataka": {
                "plant_overview": {
                    "plant_name": "JK Cement Plant",
                    "location": "Karnataka, India",
                    "capacity": {"clinker": "4000 ton/day", "cement": "4800 ton/day"},
                    "current_production": {
                        "clinker": int(sensor_data["mill-feed"]["value"] * 20),
                        "cement": int(sensor_data["mill-feed"]["value"] * 24),
                        "utilization": round(avg_efficiency, 1)
                    },
                    "key_metrics": {
                        "energy_efficiency": round(avg_efficiency, 1),
                        "quality_index": round(random.uniform(92, 96), 1),
                        "environmental_compliance": round(random.uniform(96, 99), 1),
                        "safety_score": round(random.uniform(94, 98), 1)
                    }
                },
                "focus_areas": [
                    {
                        "name": "Optimize Raw Mill Efficiency",
                        "description": "Improve grinding efficiency and reduce power consumption",
                        "metrics": [
                            {
                                "name": "Raw Mill Power",
                                "current_value": sensor_data["mill-eff"]["value"],
                                "target_value": 85.0,
                                "unit": "%",
                                "status": "good" if sensor_data["mill-eff"]["value"] > 75 else "fair",
                                "trend": sensor_data["mill-eff"]["trend"],
                                "last_updated": datetime.now().isoformat()
                            }
                        ],
                        "recommendations": [
                            {
                                "title": "Optimize Grinding Media Distribution",
                                "description": "Implement optimal ball size distribution for better grinding efficiency",
                                "priority": "high",
                                "category": "energy_efficiency",
                                "action_required": True,
                                "estimated_impact": "5-8% power reduction"
                            }
                        ],
                        "priority_score": 8.5
                    }
                ],
                "real_time_alerts": [
                    {
                        "id": f"alert_{int(time.time())}",
                        "type": "info" if avg_efficiency > 80 else "warning",
                        "title": f"Mill Efficiency: {avg_efficiency:.1f}%",
                        "description": f"Current efficiency is {'within' if avg_efficiency > 80 else 'below'} target range",
                        "severity": "low" if avg_efficiency > 80 else "medium",
                        "timestamp": datetime.now().isoformat(),
                        "location": "Mill #1",
                        "action_required": avg_efficiency < 75
                    }
                ],
                "performance_summary": {
                    "overall_score": round(avg_efficiency, 1),
                    "categories": {
                        "energy_efficiency": {"score": round(avg_efficiency, 1), "trend": "stable"},
                        "quality_performance": {"score": round(random.uniform(90, 95), 1), "trend": "stable"}
                    }
                },
                "last_updated": datetime.now().isoformat()
            }
        }
        
        # Return plant-specific data or default to karnataka
        return plant_data.get(plant, plant_data["karnataka"])
        
    except Exception as e:
        logger.error(f"Dashboard API failed: {e}")
        raise HTTPException(status_code=500, detail=f"Dashboard failed: {str(e)}")

@app.post("/api/analyze/kiln")
async def analyze_kiln_v1():
    """Kiln analysis endpoint for frontend compatibility"""
    try:
        # Get current sensor data
        current_sensors = await get_sensor_data()
        sensor_data = current_sensors["data"]
        
        # Create kiln-specific analysis prompt
        kiln_prompt = f"""
        KILN OPERATION ANALYSIS - JK CEMENT PLANT
        Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        CURRENT KILN SENSOR READINGS:
        - Preheater Temperature: {sensor_data['temp1']['value']}¬∞C (Optimal: 1200-1300¬∞C)
        - Calciner Temperature: {sensor_data['temp2']['value']}¬∞C (Optimal: 1300-1400¬∞C)
        - Kiln Inlet Temperature: {sensor_data['temp3']['value']}¬∞C (Optimal: 1000-1200¬∞C)
        - Burning Zone Temperature: {sensor_data['burning']['value']}¬∞C (Optimal: 1400-1500¬∞C)
        - Cooler Temperature: {sensor_data['cooler']['value']}¬∞C (Optimal: 150-250¬∞C)
        - Kiln Vibration: {sensor_data['vibration']['value']} mm/s (Alert: >3.0 mm/s)
        - Motor Load: {sensor_data['load']['value']}% (Optimal: 70-100%)
        - NOx Emissions: {sensor_data['emission']['value']} mg/Nm¬≥ (Limit: <500 mg/Nm¬≥)
        
        Provide comprehensive kiln analysis including:
        1. Overall operational status assessment
        2. Temperature profile analysis and recommendations
        3. Energy efficiency evaluation
        4. Environmental compliance check
        5. Safety considerations
        6. Immediate action items (if any)
        7. Short-term optimization recommendations
        
        Focus on specific, actionable recommendations with numerical targets.
        """
        
        # Get AI analysis
        analysis = await analyze_with_gemini(kiln_prompt)
        
        return {
            "text": analysis,
            "confidence": 0.95,
            "recommendations": [],
            "analysis_type": "kiln_analysis",
            "timestamp": datetime.now().isoformat(),
            "sensor_data": {
                "preheater_temp": sensor_data["temp1"]["value"],
                "calciner_temp": sensor_data["temp2"]["value"],
                "kiln_inlet_temp": sensor_data["temp3"]["value"],
                "burning_zone_temp": sensor_data["burning"]["value"],
                "cooler_temp": sensor_data["cooler"]["value"],
                "vibration": sensor_data["vibration"]["value"],
                "motor_load": sensor_data["load"]["value"],
                "nox_emissions": sensor_data["emission"]["value"]
            }
        }
        
    except Exception as e:
        logger.error(f"Kiln analysis failed: {e}")
        raise HTTPException(status_code=500, detail=f"Kiln analysis failed: {str(e)}")

@app.post("/api/analyze/mill")
async def analyze_mill_v1():
    """Mill analysis endpoint for frontend compatibility"""
    try:
        # Get current sensor data
        current_sensors = await get_sensor_data()
        sensor_data = current_sensors["data"]
        
        # Create mill-specific analysis prompt
        mill_prompt = f"""
        MILL OPERATION ANALYSIS - JK CEMENT PLANT
        Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        CURRENT MILL SENSOR READINGS:
        - Feed Rate: {sensor_data['mill-feed']['value']} t/h (Optimal: 10-15 t/h)
        - Mill Pressure: {sensor_data['mill-pressure']['value']} bar (Optimal: 1.5-2.5 bar)
        - Particle Size Distribution: {sensor_data['mill-particle']['value']} ¬µm (Target: 8-16 ¬µm)
        - Grinding Efficiency: {sensor_data['mill-eff']['value']}% (Target: >70%)
        
        Provide comprehensive mill analysis including:
        1. Mill performance assessment
        2. Grinding quality analysis (fineness, particle distribution)
        3. Energy consumption optimization potential
        4. Throughput optimization recommendations
        5. Product quality consistency evaluation
        6. Predictive maintenance insights
        7. Process control improvements
        
        Focus on:
        - Specific power consumption reduction strategies
        - Cement grinding process optimization
        - Quality parameter control recommendations
        - Equipment reliability improvements
        
        Provide actionable recommendations with measurable targets.
        """
        
        # Get AI analysis
        analysis = await analyze_with_gemini(mill_prompt)
        
        return {
            "text": analysis,
            "confidence": 0.95,
            "recommendations": [],
            "analysis_type": "mill_analysis",
            "timestamp": datetime.now().isoformat(),
            "sensor_data": {
                "feed_rate": sensor_data["mill-feed"]["value"],
                "pressure": sensor_data["mill-pressure"]["value"],
                "particle_size": sensor_data["mill-particle"]["value"],
                "efficiency": sensor_data["mill-eff"]["value"]
            }
        }
        
    except Exception as e:
        logger.error(f"Mill analysis failed: {e}")
        raise HTTPException(status_code=500, detail=f"Mill analysis failed: {str(e)}")

@app.post("/api/optimize/comprehensive")
async def comprehensive_optimization():
    """Run comprehensive plant optimization using all agents"""
    try:
        # Get current sensor data
        current_sensors = await get_sensor_data()
        sensor_data = current_sensors["data"]
        
        # Execute all agents in parallel
        optimization_tasks = []
        for agent_type, agent in agents.items():
            task_description = f"Comprehensive {agent_type} optimization analysis"
            optimization_tasks.append(agent.execute_task(task_description, sensor_data))
        
        # Wait for all agents to complete
        results = await asyncio.gather(*optimization_tasks)
        
        # Combine results
        combined_recommendations = []
        for result in results:
            if result.get("recommendations"):
                combined_recommendations.extend(result["recommendations"])
        
        # Prioritize recommendations
        critical_recommendations = [r for r in combined_recommendations if r.get("priority") == "high"]
        medium_recommendations = [r for r in combined_recommendations if r.get("priority") == "medium"]
        
        return {
            "optimization_summary": {
                "total_agents_executed": len(results),
                "total_recommendations": len(combined_recommendations),
                "critical_actions": len(critical_recommendations),
                "medium_priority": len(medium_recommendations)
            },
            "agent_results": {
                list(agents.keys())[i]: results[i] for i in range(len(results))
            },
            "prioritized_recommendations": {
                "critical": critical_recommendations,
                "medium": medium_recommendations
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Comprehensive optimization failed: {e}")
        raise HTTPException(status_code=500, detail=f"Optimization failed: {str(e)}")

@app.get("/api/simulation")
async def get_simulation_data():
    """Get enhanced kiln simulation data"""
    # Generate realistic simulation data with more parameters
    simulation_point = {
        "timestamp": datetime.now().isoformat(),
        "kiln_speed": round(random.uniform(2.8, 3.2), 2),
        "feed_rate": round(random.uniform(180, 220), 1),
        "fuel_rate": round(random.uniform(15, 25), 2),
        "oxygen_level": round(random.uniform(2.5, 4.0), 2),
        "pressure_drop": round(random.uniform(15, 25), 1),
        "clinker_temperature": round(random.uniform(1200, 1300), 1),
        "production_rate": round(random.uniform(4800, 5200), 0),
        "energy_consumption": round(random.uniform(3200, 3800), 0),
        "efficiency": round(random.uniform(85, 95), 1),
        "tsr_percentage": round(random.uniform(15, 25), 1),  # Thermal Substitution Rate
        "co2_emissions": round(random.uniform(850, 950), 0),
        "nox_emissions": round(random.uniform(200, 300), 0),
        "dust_emissions": round(random.uniform(30, 50), 1)
    }
    
    simulation_data_store.append(simulation_point)
    
    # Keep only last 100 points
    if len(simulation_data_store) > 100:
        simulation_data_store.pop(0)
    
    return {
        "status": "success",
        "timestamp": datetime.now().isoformat(),
        "data": simulation_data_store[-20:],  # Return last 20 points
        "latest": simulation_point,
        "trends": {
            "efficiency_trend": "stable",
            "emission_trend": "decreasing",
            "energy_trend": "optimizing"
        }
    }

@app.get("/api/alerts")
async def get_enhanced_alerts():
    """Get enhanced system alerts with AI insights"""
    alerts = []
    
    # Generate alerts based on sensor data
    for sensor_id, data in sensor_data_store.items():
        config = SENSORS[sensor_id]
        value = data["value"]
        
        if data["status"] == "critical":
            alerts.append({
                "id": f"critical_{sensor_id}_{int(time.time())}",
                "type": "critical",
                "sensor": sensor_id,
                "sensor_name": config["name"],
                "message": f"CRITICAL: {config['name']} at {value} {config['unit']} exceeds safe limits",
                "timestamp": datetime.now().isoformat(),
                "severity": "critical",
                "recommended_action": "Immediate intervention required",
                "estimated_impact": "High risk to safety and production"
            })
        elif data["status"] == "warning":
            alerts.append({
                "id": f"warning_{sensor_id}_{int(time.time())}",
                "type": "warning",
                "sensor": sensor_id,
                "sensor_name": config["name"],
                "message": f"WARNING: {config['name']} at {value} {config['unit']} outside optimal range",
                "timestamp": datetime.now().isoformat(),
                "severity": "medium",
                "recommended_action": "Monitor and adjust if trend continues",
                "estimated_impact": "Potential efficiency loss"
            })
    
    return {
        "status": "success",
        "timestamp": datetime.now().isoformat(),
        "alerts": alerts,
        "summary": {
            "total": len(alerts),
            "critical": len([a for a in alerts if a["severity"] == "critical"]),
            "warning": len([a for a in alerts if a["severity"] == "medium"])
        }
    }

@app.get("/api/dashboard/summary")
async def get_enhanced_dashboard_summary():
    """Get comprehensive dashboard summary with AI insights"""
    # Calculate metrics
    efficiency_sensors = ["mill-eff", "load"]
    avg_efficiency = sum(sensor_data_store[s]["value"] for s in efficiency_sensors) / len(efficiency_sensors)
    
    # Get alerts
    alerts = await get_enhanced_alerts()
    alert_summary = alerts["summary"]
    
    # Calculate production metrics
    production_rate = sensor_data_store["mill-feed"]["value"] * 24  # tons per day
    energy_consumption = random.uniform(3200, 3800)
    co2_emissions = random.uniform(850, 950)
    
    # Environmental metrics
    nox_level = sensor_data_store["emission"]["value"]
    particulate_level = sensor_data_store["particle-emission"]["value"]
    
    return {
        "status": "success",
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "overall_efficiency": round(avg_efficiency, 1),
            "production_rate_daily": round(production_rate, 0),
            "active_alerts": alert_summary["total"],
            "critical_alerts": alert_summary["critical"],
            "system_status": "critical" if alert_summary["critical"] > 0 else "warning" if alert_summary["warning"] > 2 else "normal",
            "uptime": "99.2%",
            "energy_consumption": round(energy_consumption, 0),
            "co2_emissions": round(co2_emissions, 0)
        },
        "environmental": {
            "nox_emissions": nox_level,
            "particulate_emissions": particulate_level,
            "compliance_status": "compliant" if nox_level < 400 and particulate_level < 50 else "attention_required"
        },
        "performance_indicators": {
            "thermal_efficiency": round(random.uniform(85, 95), 1),
            "grinding_efficiency": round(sensor_data_store["mill-eff"]["value"], 1),
            "fuel_efficiency": round(random.uniform(3.0, 3.5), 2),
            "quality_index": round(random.uniform(90, 98), 1)
        },
        "ai_insights": {
            "optimization_potential": "Medium - Focus on mill efficiency and fuel optimization",
            "predicted_maintenance": "Kiln refractory inspection due in 15 days",
            "energy_saving_opportunity": "5-8% reduction possible through process optimization"
        }
    }

# Background task to update sensor data
async def update_sensor_data_background():
    """Background task to continuously update sensor data"""
    while True:
        try:
            global sensor_data_store
            for sensor_id in SENSORS.keys():
                current_value = sensor_data_store[sensor_id]["value"]
                sensor_data_store[sensor_id] = generate_sensor_value(sensor_id, current_value)
            await asyncio.sleep(30)  # Update every 30 seconds
        except Exception as e:
            logger.error(f"Background sensor update failed: {e}")
            await asyncio.sleep(60)

# Background task initialization is handled in lifespan context manager

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main_updated:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
